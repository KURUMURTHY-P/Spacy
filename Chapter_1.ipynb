{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e428611a",
   "metadata": {},
   "source": [
    "# spacy\n",
    "### 1. spacy is object oriented.\n",
    "### 2.It provides most efficient nlp algorithm for a given task .\n",
    "### 3.Hence if you are care about the end result ,go with spacy.\n",
    "### 4.Prefixed setting library.\n",
    "### 5.Perfect for developers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ef679",
   "metadata": {},
   "source": [
    "## Chapter 1:          Finding words, phrases, names and concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1694d87",
   "metadata": {},
   "source": [
    " ## loading spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767d00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64730c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "Hello\n",
      "<class 'str'>\n",
      "Murthy\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "Murthy\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# creating blank nlp object and processing the text\n",
    "\n",
    "nlp =spacy.blank('en')\n",
    "# Doc object\n",
    "doc =nlp('Hello Murthy')\n",
    "\n",
    "for token in doc:\n",
    "    print(token)  \n",
    "    print(type(token))\n",
    "    print(token.text)\n",
    "    print(type(token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27a2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "murthy\n",
      "murthy.I love\n",
      "[is, .]\n"
     ]
    }
   ],
   "source": [
    "# token indexing\n",
    "doc = nlp('this is murthy.I love Statistics.')\n",
    "indicies =[token.i for token in doc]\n",
    "print(indicies)\n",
    "# printing tokens\n",
    "token_3 =doc[2]\n",
    "print(token_3)\n",
    "\n",
    "# Slicing of doc\n",
    "tokens =doc[2:6] # \".\" also consedered as one of tokens\n",
    "#print(tokens[2:6:2])  # throws an error\n",
    "print(tokens)\n",
    "print(list(doc)[1:5:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6b3d1",
   "metadata": {},
   "source": [
    "## lexical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39272039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token and index: {Apple: 0, is: 1, the: 2, first: 3, U.S.company: 4, to: 5, reach: 6, a: 7, $: 8, 1: 9, trillion: 10, .: 11}\n",
      "*******************************************************************************************************************************\n",
      "check alpha: {'Apple': True, 'is': True, 'the': True, 'first': True, 'U.S.company': False, 'to': True, 'reach': True, 'a': True, '$': False, '1': False, 'trillion': True, '.': False}\n",
      "*******************************************************************************************************************************\n",
      "{'Apple': True, 'is': True, 'the': True, 'first': True, 'U.S.company': False, 'to': True, 'reach': True, 'a': True, '$': False, '1': False, 'trillion': True, '.': False}\n",
      "*******************************************************************************************************************************\n",
      "{'Apple': False, 'is': False, 'the': False, 'first': False, 'U.S.company': False, 'to': False, 'reach': False, 'a': False, '$': False, '1': False, 'trillion': False, '.': True}\n",
      "*******************************************************************************************************************************\n",
      "{'Apple': False, 'is': False, 'the': False, 'first': True, 'U.S.company': False, 'to': False, 'reach': False, 'a': False, '$': False, '1': True, 'trillion': True, '.': False}\n"
     ]
    }
   ],
   "source": [
    " \n",
    "doc =nlp(\"Apple is the first U.S.company to reach a $1 trillion.\")\n",
    "print(\"token and index:\",dict(zip([token for token in doc],[token.i for token in doc])))\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "print(\"check alpha:\",dict(zip([token.text for token in doc],[token.is_alpha for token in doc])))\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "# check whether doc has alpha or not\n",
    "print(dict(zip([token.text for token in doc],[token.is_alpha for token in doc])))\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "# check whether doc has punctuation or not\n",
    "print(dict(zip([token.text for token in doc],[token.is_punct for token in doc])))\n",
    "\n",
    "print(\"*******************************************************************************************************************************\")\n",
    "#check whether doc has numeric or not\n",
    "print(dict(zip([token.text for token in doc],[token.like_num for token in doc])))\n",
    "\n",
    "# like_url & like_mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f49055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c06e19",
   "metadata": {},
   "source": [
    "## Trained pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91ef1655",
   "metadata": {},
   "source": [
    "What are trained pipelines?\n",
    "Models that enable spaCy to predict linguistic attributes in context\n",
    "Part-of-speech tags\n",
    "Syntactic dependencies\n",
    "Named entities\n",
    "Trained on labeled example texts\n",
    "Can be updated with more examples to fine-tune predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb786df4",
   "metadata": {},
   "source": [
    "## Loading pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b2a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
     ]
    }
   ],
   "source": [
    "# Load the \"en_core_web_sm\" pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d76ecf",
   "metadata": {},
   "source": [
    "## Predicting linguistic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355aa28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "’s          VERB      ROOT      \n",
      "official    ADJ       acomp     \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0bdc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple : ORG\n",
      "first : ORDINAL\n",
      "U.S. : GPE\n",
      "$1 trillion : MONEY\n"
     ]
    }
   ],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the doc.ents and print the entity text and label_ attribute.\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text,\":\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66927f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3] \n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93ab0f",
   "metadata": {},
   "source": [
    "## Predicting name entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f024bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f656a1",
   "metadata": {},
   "source": [
    "## Rule based matching"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bcc0f8c",
   "metadata": {},
   "source": [
    "Why not just regular expressions?\n",
    "Match on Doc objects, not just strings\n",
    "Match on tokens and token attributes\n",
    "Use a model's predictions\n",
    "Example: \"duck\" (verb) vs. \"duck\" (noun)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f8dd29e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ef0fd67",
   "metadata": {},
   "source": [
    "### 1. Using the matcher "
   ]
  },
  {
   "cell_type": "raw",
   "id": "26cd7458",
   "metadata": {},
   "source": [
    "lexical attributes\n",
    "1.pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"token\"},\n",
    "    {\"LOWER\": \"token\"},\n",
    "    {\"LOWER\": \"token\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "2.pattern = [\n",
    "    {\"LEMMA\": \"token\", \"POS\": \"POS\"},\n",
    "    {\"POS\": \"POS\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce445440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a pipeline and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20390d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span is: iPhone X\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(\"matched span is:\",matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494582f9",
   "metadata": {},
   "source": [
    "### 2.Using Matcher"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37444b1e",
   "metadata": {},
   "source": [
    "match_id: hash value of the pattern name\n",
    "start: start index of matched span\n",
    "end: end index of matched span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226bb9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span is: loved dogs\n",
      "matched span is: love cats\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "matcher.add(\"pattern\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"I loved dogs but now I love cats more.\")\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(\"matched span is:\",matched_span.text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d2d4f1a",
   "metadata": {},
   "source": [
    "\n",
    "Example       \tDescription\n",
    "{\"OP\": \"!\"}\t   Negation: match 0 times\n",
    "{\"OP\": \"?\"}\t   Optional: match 0 or 1 times\n",
    "{\"OP\": \"+\"}\t   Match 1 or more times\n",
    "{\"OP\": \"*\"}\t   Match 0 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad9186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span is: bought a smartphone\n",
      "matched span is: buying apps\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},  # optional: match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "matcher.add(\"pattern\", [pattern])\n",
    "# Process some text\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(\"matched span is:\",matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adb6752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a51ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found: beautiful design\n",
      "Match found: smart search\n",
      "Match found: automatic labels\n",
      "Match found: optional voice\n",
      "Match found: optional voice responses\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Features of the app include a beautiful design, smart search, automatic \"\n",
    "          \"labels and optional voice responses.\")\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a72b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"green fund is a corporation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb2e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "D =nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b9eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction via add_pipe\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "# Construction from class\n",
    "from spacy.pipeline import EntityRuler\n",
    "ruler = EntityRuler(nlp, overwrite_ents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf8e0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrn =[{'LOWER':'green'},{\"LOWER\":\"fund\"},{\"ORTH\":\"is\"},{\"LOWER\":\"corportaion\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8567ebfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mruler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptrn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\entityruler.py:303\u001b[0m, in \u001b[0;36mEntityRuler.add_patterns\u001b[1;34m(self, patterns)\u001b[0m\n\u001b[0;32m    301\u001b[0m phrase_pattern_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpattern\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    304\u001b[0m         phrase_pattern_labels\u001b[38;5;241m.\u001b[39mappend(entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    305\u001b[0m         phrase_pattern_texts\u001b[38;5;241m.\u001b[39mappend(entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pattern'"
     ]
    }
   ],
   "source": [
    "ruler.add_patterns(ptrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c183cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
